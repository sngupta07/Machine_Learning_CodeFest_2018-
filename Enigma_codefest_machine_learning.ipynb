{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enigma codeFest Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The competition has been organised by [Analytics Vidhya](https://datahack.analyticsvidhya.com/contest/enigma-codefest-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is regression based problem and we have to predict the no. of upvotes given by the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation metric used is RMSE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "samp= pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52664</td>\n",
       "      <td>a</td>\n",
       "      <td>3942.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155623</td>\n",
       "      <td>7855.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327662</td>\n",
       "      <td>a</td>\n",
       "      <td>26046.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21781</td>\n",
       "      <td>55801.0</td>\n",
       "      <td>1175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468453</td>\n",
       "      <td>c</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56177</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96996</td>\n",
       "      <td>a</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>168793</td>\n",
       "      <td>27064.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131465</td>\n",
       "      <td>c</td>\n",
       "      <td>4271.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112223</td>\n",
       "      <td>13986.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID Tag  Reputation  Answers  Username    Views  Upvotes\n",
       "0   52664   a      3942.0      2.0    155623   7855.0     42.0\n",
       "1  327662   a     26046.0     12.0     21781  55801.0   1175.0\n",
       "2  468453   c      1358.0      4.0     56177   8067.0     60.0\n",
       "3   96996   a       264.0      3.0    168793  27064.0      9.0\n",
       "4  131465   c      4271.0      4.0    112223  13986.0     83.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First method used is ANN with three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le= LabelEncoder()\n",
    "encoder= le.fit(train['Tag'].astype(str))\n",
    "train['Tag']= encoder.transform(train['Tag'])\n",
    "test['Tag']= encoder.transform(test['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(train.drop(['ID', 'Username', 'Upvotes'], axis=1), train['Upvotes'],\n",
    "                                                   random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 247533 samples, validate on 82512 samples\n",
      "Epoch 1/5\n",
      "247533/247533 [==============================] - 4s 16us/step - loss: 14926505.5474 - mean_squared_error: 14926505.5474 - val_loss: 7298567.4873 - val_mean_squared_error: 7298567.4873\n",
      "Epoch 2/5\n",
      "247533/247533 [==============================] - 3s 13us/step - loss: 14926505.5526 - mean_squared_error: 14926505.5526 - val_loss: 7298567.4873 - val_mean_squared_error: 7298567.4873\n",
      "Epoch 3/5\n",
      "247533/247533 [==============================] - 4s 16us/step - loss: 14926505.6764 - mean_squared_error: 14926505.6764 - val_loss: 7298567.4873 - val_mean_squared_error: 7298567.4873\n",
      "Epoch 4/5\n",
      "247533/247533 [==============================] - 4s 15us/step - loss: 14926505.6978 - mean_squared_error: 14926505.6978 - val_loss: 7298567.4873 - val_mean_squared_error: 7298567.4873\n",
      "Epoch 5/5\n",
      "247533/247533 [==============================] - 4s 15us/step - loss: 14926505.8649 - mean_squared_error: 14926505.8649 - val_loss: 7298567.4873 - val_mean_squared_error: 7298567.4873\n",
      "247533/247533 [==============================] - 1s 4us/step\n",
      "82512/82512 [==============================] - 0s 4us/step\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8ac6755c9b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mr_squared\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right, name, na_op)\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m         return construct_result(\n\u001b[0;32m    741\u001b[0m             \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[1;34m(lvalues, rvalues)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m                                              'b_value': b_value},\n\u001b[0;32m    109\u001b[0m                                  \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'safe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                                  **eval_kwargs)\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'unknown type object'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numexpr\\necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[0m_numexpr_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompiled_ex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mevaluate_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcompiled_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(units= 100, activation= 'relu', kernel_initializer= 'uniform', input_dim= X_train.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units= 10, activation= 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units= 1, activation= 'relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics= [mean_squared_error])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size= 200, epochs= 5, validation_data= (X_test, y_test))\n",
    "\n",
    "y_pred= model.predict(X_test, batch_size= 200)\n",
    "\n",
    "#print accuracies\n",
    "train_acc= model.evaluate(X_train, y_train, batch_size= 200)\n",
    "test_acc= model.evaluate(X_test, y_test, batch_size= 200)\n",
    "r_squared= r2_score(y_test, y_pred)\n",
    "mse= mean_squared_error(y_test, y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "\n",
    "print('Train detail', train_acc)\n",
    "print('Test detail', test_acc)\n",
    "print('r_squared: {}' .format(r_squared))\n",
    "print('rmse: {}' .format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Reputation_Views_Ratio']= train['Reputation']/train['Views']\n",
    "test['Reputation_Views_Ratio']= test['Reputation']/test['Views']\n",
    "\n",
    "train['Answers_Views_Ratio']= train['Answers']/train['Views']\n",
    "test['Answers_Views_Ratio']= test['Answers']/test['Views']\n",
    "\n",
    "train['Views_Scale']= train['Views']/train['Views'].mean()\n",
    "test['Views_Scale']= test['Views']/test['Views'].mean()\n",
    "\n",
    "train['Reputation_Scale']= train['Reputation']/train['Reputation'].mean()\n",
    "test['Reputation_Scale']= test['Reputation']/test['Reputation'].mean()\n",
    "\n",
    "train['Answers_Scale']= train['Answers']/train['Answers'].mean()\n",
    "test['Answers_Scale']= test['Answers']/test['Answers'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Reputation_Views_Ratio</th>\n",
       "      <th>Answers_Views_Ratio</th>\n",
       "      <th>Views_Scale</th>\n",
       "      <th>Reputation_Scale</th>\n",
       "      <th>Answers_Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52664</td>\n",
       "      <td>0</td>\n",
       "      <td>3942.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155623</td>\n",
       "      <td>7855.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.501846</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.264968</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.510507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327662</td>\n",
       "      <td>0</td>\n",
       "      <td>26046.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21781</td>\n",
       "      <td>55801.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>0.466766</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1.882303</td>\n",
       "      <td>3.350767</td>\n",
       "      <td>3.063044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468453</td>\n",
       "      <td>1</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56177</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.272119</td>\n",
       "      <td>0.174704</td>\n",
       "      <td>1.021015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96996</td>\n",
       "      <td>0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>168793</td>\n",
       "      <td>27064.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.912934</td>\n",
       "      <td>0.033963</td>\n",
       "      <td>0.765761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131465</td>\n",
       "      <td>1</td>\n",
       "      <td>4271.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112223</td>\n",
       "      <td>13986.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.305377</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.471782</td>\n",
       "      <td>0.549456</td>\n",
       "      <td>1.021015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Tag  Reputation  Answers  Username    Views  Upvotes  \\\n",
       "0   52664    0      3942.0      2.0    155623   7855.0     42.0   \n",
       "1  327662    0     26046.0     12.0     21781  55801.0   1175.0   \n",
       "2  468453    1      1358.0      4.0     56177   8067.0     60.0   \n",
       "3   96996    0       264.0      3.0    168793  27064.0      9.0   \n",
       "4  131465    1      4271.0      4.0    112223  13986.0     83.0   \n",
       "\n",
       "   Reputation_Views_Ratio  Answers_Views_Ratio  Views_Scale  Reputation_Scale  \\\n",
       "0                0.501846             0.000255     0.264968          0.507131   \n",
       "1                0.466766             0.000215     1.882303          3.350767   \n",
       "2                0.168340             0.000496     0.272119          0.174704   \n",
       "3                0.009755             0.000111     0.912934          0.033963   \n",
       "4                0.305377             0.000286     0.471782          0.549456   \n",
       "\n",
       "   Answers_Scale  \n",
       "0       0.510507  \n",
       "1       3.063044  \n",
       "2       1.021015  \n",
       "3       0.765761  \n",
       "4       1.021015  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Reputation']= train['Reputation'].astype(int)\n",
    "test['Reputation']= test['Reputation'].astype(int)\n",
    "\n",
    "train['Answers']= train['Answers'].astype(int)\n",
    "test['Answers']= test['Answers'].astype(int)\n",
    "\n",
    "train['Views']= train['Views'].astype(int)\n",
    "test['Views']= test['Views'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(train.drop(['ID', 'Username', 'Upvotes'], axis= 1),\n",
    "                                                   train['Upvotes'], random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat_index= np.where(train.drop(['ID', 'Username', 'Upvotes'], axis= 1).dtypes!= np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CB(train, target, test, cat_feat_index= cat_feat_index):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "    X_train, X_test, y_train, y_test= train_test_split(train, target, random_state= 0)\n",
    "    param_cb= {}\n",
    "    param_cb['iterations']= 1000\n",
    "    param_cb['learning_rate']= 0.1\n",
    "    #param_cb['max_depth']= 3\n",
    "    #param_cb['random_seed']= 2018\n",
    "    model= cb.CatBoostRegressor(**param_cb)\n",
    "    \n",
    "    model.fit(X_train, y_train, cat_feat_index, eval_set= (X_test, y_test), verbose= 100, early_stopping_rounds= 50)\n",
    "    \n",
    "    y_pred= model.predict(X_test)\n",
    "    \n",
    "    r_squared= r2_score(y_test, y_pred)\n",
    "    mse= mean_squared_error(y_test, y_pred)\n",
    "    rmse= np.sqrt(mse)\n",
    "    #msle= mean_squared_log_error(y_test, y_pred)\n",
    "    #rmsle= np.sqrt(msle)\n",
    "    print('The R-Squared value: {:.4f}' .format(r_squared))\n",
    "    print('Mean Squared Error: {:.4f}' .format(mse))\n",
    "    print('Root Mean Squared Error: {:.4f}' .format(rmse))\n",
    "    #print('Root Mean Squared Log Error: {:.4f}' .format(rmsle))\n",
    "    \n",
    "    return model, model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3692.4595896\ttest: 2569.1815115\tbest: 2569.1815115 (0)\ttotal: 790ms\tremaining: 13m 8s\n",
      "100:\tlearn: 1051.7016295\ttest: 1059.9045170\tbest: 1059.9045170 (100)\ttotal: 50.3s\tremaining: 7m 27s\n",
      "200:\tlearn: 814.6666365\ttest: 1006.4085183\tbest: 1005.9317449 (184)\ttotal: 1m 39s\tremaining: 6m 35s\n",
      "300:\tlearn: 719.4999745\ttest: 987.4857834\tbest: 987.3361094 (297)\ttotal: 2m 29s\tremaining: 5m 46s\n",
      "400:\tlearn: 645.3981486\ttest: 982.0289381\tbest: 979.1885596 (375)\ttotal: 3m 19s\tremaining: 4m 57s\n",
      "500:\tlearn: 588.3221075\ttest: 978.7037999\tbest: 976.1758268 (471)\ttotal: 4m 9s\tremaining: 4m 8s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 976.1758268\n",
      "bestIteration = 471\n",
      "\n",
      "Shrink model to first 472 iterations.\n",
      "The R-Squared value: 0.8675\n",
      "Mean Squared Error: 952919.2448\n",
      "Root Mean Squared Error: 976.1758\n"
     ]
    }
   ],
   "source": [
    "model_1, pred_1= run_CB(train.drop(['ID', 'Username', 'Upvotes'], axis= 1), train['Upvotes'],\n",
    "                        test.drop(['ID', 'Username'], axis= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ml_modeling(model, train, target, test):\n",
    "    from sklearn.metrics import r2_score, mean_squared_error\n",
    "    X_train, X_test, y_train, y_test= train_test_split(train, target, random_state= 0)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred= model.predict(X_test)\n",
    "    \n",
    "    r_squared= r2_score(y_test, y_pred)\n",
    "    mse= mean_squared_error(y_test, y_pred)\n",
    "    rmse= np.sqrt(mse)\n",
    "    #msle= mean_squared_log_error(y_test, y_pred)\n",
    "    #rmsle= np.sqrt(msle)\n",
    "    print('The R-Squared value: {:.4f}' .format(r_squared))\n",
    "    print('Mean Squared Error: {:.4f}' .format(mse))\n",
    "    print('Root Mean Squared Error: {:.4f}' .format(rmse))\n",
    "    #print('Root Mean Squared Log Error: {:.4f}' .format(rmsle))\n",
    "    \n",
    "    return model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lin= LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-Squared value: 0.3333\n",
      "Mean Squared Error: 4795905.4603\n",
      "Root Mean Squared Error: 2189.9556\n"
     ]
    }
   ],
   "source": [
    "pred_2= ml_modeling(reg_lin, train.drop(['ID', 'Username', 'Upvotes'], axis= 1), train['Upvotes'],\n",
    "                        test.drop(['ID', 'Username'], axis= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_XGB(train, target, test):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "    X_train, X_test, y_train, y_test= train_test_split(train, target, random_state= 0)\n",
    "    \n",
    "    param_xgb= {}\n",
    "    param_xgb['eta']= 0.1\n",
    "    param_xgb['objective']= 'reg:linear'\n",
    "    param_xgb['subsample']= 0.8\n",
    "    param_xgb['colsample_bytree']= 0.7\n",
    "    param_xgb['max_depth']= 3\n",
    "    param_xgb['eval_metric']= 'rmse'\n",
    "    param_xgb['seed']= 0\n",
    "    \n",
    "    dtrain= xgb.DMatrix(X_train, y_train, silent= True)\n",
    "    dtest= xgb.DMatrix(X_test, y_test, silent= True)\n",
    "    test_= xgb.DMatrix(test)\n",
    "\n",
    "    watchlist= [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    \n",
    "    model= xgb.train(param_xgb, dtrain, 1000, watchlist, early_stopping_rounds= 50, verbose_eval= 100)\n",
    "    \n",
    "    y_pred= model.predict(dtest)\n",
    "\n",
    "    r_squared= r2_score(y_test, y_pred)\n",
    "    mse= mean_squared_error(y_test, y_pred)\n",
    "    rmse= np.sqrt(mse)\n",
    "    #msle= mean_squared_log_error(y_test, y_pred)\n",
    "    #rmsle= np.sqrt(msle)\n",
    "    print('The R-Squared value: {:.4f}' .format(r_squared))\n",
    "    print('Mean Squared Error: {:.4f}' .format(mse))\n",
    "    print('Root Mean Squared Error: {:.4f}' .format(rmse))\n",
    "    #print('Root Mean Squared Log Error: {:.4f}' .format(rmsle))\n",
    "    \n",
    "    return model.predict(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:2585.05\ttrain-rmse:3655.52\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 50 rounds.\n",
      "[100]\teval-rmse:861.942\ttrain-rmse:776.137\n",
      "[200]\teval-rmse:902.681\ttrain-rmse:632.025\n",
      "[300]\teval-rmse:930.063\ttrain-rmse:559.611\n",
      "[400]\teval-rmse:931.952\ttrain-rmse:515.458\n",
      "[500]\teval-rmse:943.385\ttrain-rmse:479.87\n",
      "[600]\teval-rmse:952.558\ttrain-rmse:457.164\n",
      "[700]\teval-rmse:958.32\ttrain-rmse:435.768\n",
      "[800]\teval-rmse:966.928\ttrain-rmse:419.903\n",
      "[900]\teval-rmse:967.309\ttrain-rmse:405.383\n",
      "[999]\teval-rmse:970.289\ttrain-rmse:391.61\n",
      "The R-Squared value: 0.8691\n",
      "Mean Squared Error: 941460.8451\n",
      "Root Mean Squared Error: 970.2891\n"
     ]
    }
   ],
   "source": [
    "pred_4= run_XGB(train.drop(['ID', 'Username', 'Upvotes'], axis= 1), train['Upvotes'],\n",
    "                test.drop(['ID', 'Username'], axis= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_XGB(train, target, test):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "    X_train, X_test, y_train, y_test= train_test_split(train, target, random_state= 0, test_size= 0.15)\n",
    "    \n",
    "    param_xgb= {}\n",
    "    param_xgb['eta']= 0.1\n",
    "    param_xgb['objective']= 'reg:linear'\n",
    "    param_xgb['subsample']= 0.8\n",
    "    param_xgb['colsample_bytree']= 0.7\n",
    "    param_xgb['max_depth']= 3\n",
    "    param_xgb['eval_metric']= 'rmse'\n",
    "    param_xgb['seed']= 0\n",
    "    \n",
    "    dtrain= xgb.DMatrix(X_train, y_train, silent= True)\n",
    "    dtest= xgb.DMatrix(X_test, y_test, silent= True)\n",
    "    test_= xgb.DMatrix(test)\n",
    "\n",
    "    watchlist= [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    \n",
    "    model= xgb.train(param_xgb, dtrain, 1000, watchlist, early_stopping_rounds= 50, verbose_eval= 100)\n",
    "    \n",
    "    y_pred= model.predict(dtest)\n",
    "\n",
    "    r_squared= r2_score(y_test, y_pred)\n",
    "    mse= mean_squared_error(y_test, y_pred)\n",
    "    rmse= np.sqrt(mse)\n",
    "    #msle= mean_squared_log_error(y_test, y_pred)\n",
    "    #rmsle= np.sqrt(msle)\n",
    "    print('The R-Squared value: {:.4f}' .format(r_squared))\n",
    "    print('Mean Squared Error: {:.4f}' .format(mse))\n",
    "    print('Root Mean Squared Error: {:.4f}' .format(rmse))\n",
    "    #print('Root Mean Squared Log Error: {:.4f}' .format(rmsle))\n",
    "    \n",
    "    return model.predict(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_= pd.read_csv('train.csv')\n",
    "test_= pd.read_csv('test.csv')\n",
    "samp= pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['Tag']= le.fit_transform(train_['Tag'].astype(str))\n",
    "test_['Tag']= le.fit_transform(test_['Tag'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:2621.47\ttrain-rmse:3500.65\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 50 rounds.\n",
      "[100]\teval-rmse:827.61\ttrain-rmse:760.952\n",
      "[200]\teval-rmse:840.4\ttrain-rmse:625.349\n",
      "[300]\teval-rmse:848.906\ttrain-rmse:564.636\n",
      "[400]\teval-rmse:857.448\ttrain-rmse:514.769\n",
      "[500]\teval-rmse:861.676\ttrain-rmse:483.894\n",
      "[600]\teval-rmse:876.373\ttrain-rmse:463.058\n",
      "[700]\teval-rmse:879.001\ttrain-rmse:444.33\n",
      "[800]\teval-rmse:883.476\ttrain-rmse:426.683\n",
      "[900]\teval-rmse:888.642\ttrain-rmse:412.349\n",
      "[999]\teval-rmse:898.327\ttrain-rmse:401.482\n",
      "The R-Squared value: 0.8942\n",
      "Mean Squared Error: 806992.1483\n",
      "Root Mean Squared Error: 898.3274\n"
     ]
    }
   ],
   "source": [
    "pred_7= run_XGB(train.drop(['ID', 'Upvotes'], axis= 1), train['Upvotes'],\n",
    "                test.drop(['ID'], axis= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here, I got the best result i.e. RMSE of 898.3274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_12= pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'Upvotes': pred_7\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_12.to_csv('sample_12.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LGBM(train, target, test):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "    X_train, X_test, y_train, y_test= train_test_split(train, target, random_state= 2018)\n",
    "    \n",
    "    param_lgbm= {}\n",
    "    param_lgbm['learning_rate']= 0.1\n",
    "    param_lgbm['objective']= 'regression'\n",
    "    param_lgbm['num_iterations']= 10000\n",
    "    param_lgbm['num_threads']= 7\n",
    "    param_lgbm['seed']= 0\n",
    "    #param_lgbm['max_depth']= 3\n",
    "    param_lgbm['early_stopping_round']= 50\n",
    "    #param_lgbm['verbose']= 100\n",
    "    param_lgbm['metric']= 'rmse'\n",
    "    \n",
    "    dtrain= lgbm.Dataset(X_train, y_train, silent= True)\n",
    "    dtest= lgbm.Dataset(X_test, y_test, silent= True)\n",
    "    \n",
    "    model= lgbm.train(param_lgbm, dtrain, valid_sets= [dtrain, dtest], verbose_eval= 100)\n",
    "    \n",
    "    y_pred= model.predict(X_test)\n",
    "\n",
    "    r_squared= r2_score(y_test, y_pred)\n",
    "    mse= mean_squared_error(y_test, y_pred)\n",
    "    rmse= np.sqrt(mse)\n",
    "    #msle= mean_squared_log_error(y_test, y_pred)\n",
    "    #rmsle= np.sqrt(msle)\n",
    "    print('The R-Squared value: {:.4f}' .format(r_squared))\n",
    "    print('Mean Squared Error: {:.4f}' .format(mse))\n",
    "    print('Root Mean Squared Error: {:.4f}' .format(rmse))\n",
    "    #print('Root Mean Squared Log Error: {:.4f}' .format(rmsle))\n",
    "    \n",
    "    return model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sngupta\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\sngupta\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 1024.24\tvalid_1's rmse: 1692.53\n",
      "[200]\ttraining's rmse: 770.82\tvalid_1's rmse: 1628.78\n",
      "[300]\ttraining's rmse: 638.169\tvalid_1's rmse: 1591.78\n",
      "[400]\ttraining's rmse: 566.011\tvalid_1's rmse: 1584.38\n",
      "[500]\ttraining's rmse: 519.451\tvalid_1's rmse: 1579.29\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's rmse: 540.934\tvalid_1's rmse: 1578.56\n",
      "The R-Squared value: 0.8119\n",
      "Mean Squared Error: 2491842.6421\n",
      "Root Mean Squared Error: 1578.5571\n"
     ]
    }
   ],
   "source": [
    "pred_8= run_LGBM(train.drop(['ID', 'Upvotes', 'Username'], axis= 1), train['Upvotes'],\n",
    "                test.drop(['ID', 'Username'], axis= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In my case the XGBoost algorithm gave the best result among all these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
